


@ARTICLE{Metz2023-qz,
  title     = "Chatbots May `Hallucinate' More Often Than Many Realize",
  author    = "Metz, Cade",
  abstract  = "When summarizing facts, ChatGPT technology makes things up about
               3 percent of the time, according to research from a new
               start-up. A Google system's rate was 27 percent.",
  journal   = "The New York Times",
  publisher = "The New York Times",
  month     =  nov,
  year      =  2023,
  language  = "en"
}



@ARTICLE{Huang2023-zf,
  title         = "A Survey on Hallucination in Large Language Models:
                   Principles, Taxonomy, Challenges, and Open Questions",
  author        = "Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong,
                   Weihong and Feng, Zhangyin and Wang, Haotian and Chen,
                   Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing
                   and Liu, Ting",
  abstract      = "The emergence of large language models (LLMs) has marked a
                   significant breakthrough in natural language processing
                   (NLP), leading to remarkable advancements in text
                   understanding and generation. Nevertheless, alongside these
                   strides, LLMs exhibit a critical tendency to produce
                   hallucinations, resulting in content that is inconsistent
                   with real-world facts or user inputs. This phenomenon poses
                   substantial challenges to their practical deployment and
                   raises concerns over the reliability of LLMs in real-world
                   scenarios, which attracts increasing attention to detect and
                   mitigate these hallucinations. In this survey, we aim to
                   provide a thorough and in-depth overview of recent advances
                   in the field of LLM hallucinations. We begin with an
                   innovative taxonomy of LLM hallucinations, then delve into
                   the factors contributing to hallucinations. Subsequently, we
                   present a comprehensive overview of hallucination detection
                   methods and benchmarks. Additionally, representative
                   approaches designed to mitigate hallucinations are
                   introduced accordingly. Finally, we analyze the challenges
                   that highlight the current limitations and formulate open
                   questions, aiming to delineate pathways for future research
                   on hallucinations in LLMs.",
  month         =  nov,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2311.05232"
}


@ARTICLE{Zhang2023-ok,
  title         = "Siren's Song in the {AI} Ocean: A Survey on Hallucination in
                   Large Language Models",
  author        = "Zhang, Yue and Li, Yafu and Cui, Leyang and Cai, Deng and
                   Liu, Lemao and Fu, Tingchen and Huang, Xinting and Zhao,
                   Enbo and Zhang, Yu and Chen, Yulong and Wang, Longyue and
                   Luu, Anh Tuan and Bi, Wei and Shi, Freda and Shi, Shuming",
  abstract      = "While large language models (LLMs) have demonstrated
                   remarkable capabilities across a range of downstream tasks,
                   a significant concern revolves around their propensity to
                   exhibit hallucinations: LLMs occasionally generate content
                   that diverges from the user input, contradicts previously
                   generated context, or misaligns with established world
                   knowledge. This phenomenon poses a substantial challenge to
                   the reliability of LLMs in real-world scenarios. In this
                   paper, we survey recent efforts on the detection,
                   explanation, and mitigation of hallucination, with an
                   emphasis on the unique challenges posed by LLMs. We present
                   taxonomies of the LLM hallucination phenomena and evaluation
                   benchmarks, analyze existing approaches aiming at mitigating
                   LLM hallucination, and discuss potential directions for
                   future research.",
  month         =  sep,
  year          =  2023,
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL",
  eprint        = "2309.01219"
}


@BOOK{Fay2021-ta,
  title     = "Engineering {Production-Grade} Shiny Apps",
  author    = "Fay, Colin and Rochette, S{\'e}bastien and Guyader, Vincent and
               Girard, Cervan",
  publisher = "CRC Press",
  month     =  sep,
  year      =  2021,
  language  = "en"
}


@INCOLLECTION{Friendly2006-aq,
  title     = "A Brief History of Data Visualization",
  booktitle = "Handbook of Data Visualization",
  author    = "Friendly, Michael",
  publisher = "Springer Berlin Heidelberg",
  pages     = "15-56",
  series    = "Springer Handbooks Comp.Statistics",
  year      =  2006,
  keywords  = "Paper: Visualizing causality;Visualization;Seminar: Data
               Visualization",
  language  = "en"
}


@ARTICLE{Cleveland1984-fy,
  title     = "Graphical Perception: Theory, Experimentation, and Application
               to the Development of Graphical Methods",
  author    = "Cleveland, William S and McGill, Robert",
  journal   = "Journal of the American Statistical Association",
  publisher = "Taylor \& Francis, Ltd. on behalf of the American Statistical
               Association",
  volume    =  79,
  number    =  387,
  pages     = "531-554",
  month     =  "1~" # sep,
  year      =  1984,
  keywords  = "Visualization;Course: Data Visualization"
}



@ARTICLE{Anscombe1973-xv,
  title     = "Graphs in Statistical Analysis",
  author    = "Anscombe, F J",
  journal   = "Am. Stat.",
  publisher = "Taylor \& Francis",
  volume    =  27,
  number    =  1,
  pages     = "17--21",
  month     =  feb,
  year      =  1973
}

@ARTICLE{Swayne1999-wf,
  title   = "Introduction to the special issue on interactive graphical data
             analysis: What is interaction?",
  author  = "Swayne, Deborah",
  journal = "Computational statistics",
  volume  =  14,
  number  =  1,
  pages   = "1-6",
  year    =  1999
}


@Manual{rcoreteam2023,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2023},
    url = {https://www.R-project.org/},
  }

@Manual{chang2020,
    title = {shiny: Web Application Framework for R},
    author = {Winston Chang and Joe Cheng and JJ Allaire and Carson Sievert and Barret Schloerke and Yihui Xie and Jeff Allen and Jonathan McPherson and Alan Dipert and Barbara Borges},
    year = {2022},
    note = {R package version 1.7.4},
    url = {https://CRAN.R-project.org/package=shiny},
  }

@book{wickham2016,
    author = {Hadley Wickham},
    title = {ggplot2: Elegant Graphics for Data Analysis},
    publisher = {Springer-Verlag New York},
    year = {2016},
    isbn = {978-3-319-24277-4},
    url = {https://ggplot2.tidyverse.org},
  }

@book{sievert2020,
    author = {Carson Sievert},
    title = {Interactive Web-Based Data Visualization with R, plotly, and shiny},
    publisher = {Chapman and Hall/CRC},
    year = {2020},
    isbn = {9781138331457},
    url = {https://plotly-r.com},
  }

@book{wickham2021mastering,
  title={Mastering shiny},
  author={Wickham, Hadley},
  year={2021},
  publisher={" O'Reilly Media, Inc."}
}



@MISC{Bertini2017-jq,
  title        = "From Data Visualization to Interactive Data Analysis",
  booktitle    = "Medium",
  author       = "Bertini, Enrico",
  abstract     = "",
  month        =  nov,
  year         =  2017,
  howpublished = "\url{https://medium.com/@FILWD/from-data-visualization-to-interactive-data-analysis-e24ae3751bf3}",
  note         = "Accessed: 2023-6-14",
  language     = "en"
}
