--- 
title: "Introduction"
---

- Learning outcomes: 
  - Understand idea/aims/advantages/steps of interactive data analysis
  - Understand basic structure of Shiny apps
  - Launch first app
  - Understand logic of reactivity/loading things in Shiny apps
  - Discuss MVP and workflow


```{r message=FALSE, warning=FALSE, include=FALSE}
# install.packages("pacman)
pacman::p_load(knitr, quarto, tidyverse, gganimate, kableExtra)
```

Sources: [@Bertini2017-jq, @wickham2021mastering]

## Interactive data analysis

Sources: [@Bertini2017-jq]

### Why?
- "From Data Visualization to Interactive Data Analysis" [@Bertini2017-jq]
- Main uses of data visualization: Inspirational, explanatory and analytical^[**Inspirational**. The main goal here is to inspire people. To wow them! But not just on a superficial level, but to really engage people into deeper thinking, sense of beauty and awe. **Explanatory**. The main goal here is to use graphics as a way to explain some complex idea, phenomenon or process. **Analytical**. The main goal here is to extract information out of data with the purpose of answering questions and advancing understanding of some phenomenon of interest.]
- "data analysis [...] can help people improve their understanding of complex phenomena"
  - *"if I understand a problem better, there are higher chances I can find a better solution for it"*
  - **Main goal of (interactive) data analysis**: "understanding" something
- @fig-bertini-one outlines the relationship between reality, data/statistical models, human mental models 
  - Humans have a mental model of the reality and use data and models (= description of reality) to study it so that they can hopefully understand it better


![Relationship between reality, data/statistical models, human mental models (Source: Bertini, 2017)](02-bertinin-1.webp){#fig-bertini-one}

### How Does Interactive Data Analysis Work?
- @fig-bertini-two outlines process underlying interactive data analysis
  - **Loop fashion**: start with loosely specified goal, translate goal into one or more questions, organize and analyze the data to answer these questions, generate new questions and start over

![Process underlying interactive data analysis (Source: Bertini, 2017)](02-bertinin-2.webp){#fig-bertini-two}

### Steps of interactive data analysis 
1. **Defining the problem**: What problem are you trying to solve? What is your ultimate goal? How is increased understanding derived from data analysis going to bring you closer to your goal?
2. **Generating questions**: Problem is typically too high-level and loosely specified to translate into data analysis. The problem needs to be translated (implicitly or, better, explicitly) into number of data analysis questions.
3. **Gathering, transforming and familiarizing with the data**: all projects require analysts to familiarize with the content and its meaning and perform multiple transformations, both to familiarize with the data (e.g., often slicing, dicing and aggregating the data) and to prepare it for the analysis one is planning to perform.
4. **Creating models out of data** (not always): using statistical modeling and machine learning methods can be useful when the question asked can be answered more easily by building a model, e.g., explanatory or predictive ML model such as regression, clustering, NLP
5. **Visualizing data and models**: results obtained from data transformation and querying (or from some model) are turned into something our **eyes can digest** and hopefully understand. **Simple representations** like tables and lists rather than fancy charts are perfectly reasonable visualization for many problems. 
6. **Interpreting the results**: once results have been generated and represented in visual format, they need to be interpreted by someone (crucial step!)
    - complex activity including: understanding how to read the graph, understanding what graph communicates about phenomenon of interest, linking results to questions and pre-existing knowledge of problem
    - Interpretation heavily influenced by pre-existing knowledge (about domain problem, data transformation process, modeling, visual representation)
7. **Generating inferences and more questions**: steps above lead to creating new knowledge, additional questions or hypotheses
    - Outcome: not only answers but also (hopefully better, more refined) questions


### Important aspects of data analysis & Quo vadis interaction?
- The process is not sequential and is highly iterative (jumping back/forth between steps)
- Some activities are exclusively human, e.g., defining problems, generating questions, etc.
- Visualization is just a small portion of the process and effectiveness depends on all steps above
- **Interaction**: all over the place... every time you tell your computer what to do and you computer returns some information back to you
  - Gather and transform the data
  - Specify a model and/or a query from the data
  - Specify how to represent the results (and the model)
  - Browse the results
  - Synthesize and communicate the facts gathered
- **Direct Manipulation vs. Command-Line Interaction**: Besides [WIMP](https://en.wikipedia.org/wiki/WIMP_(computing)) interfaces, direct manipulation, clicks, mouse overs, etc., command line interface is also interactive ("modely" changes: (dis-)advantages?)




### Challenges of Interactive Visual Data Analysis
- **Specification (Mind &rarr; Data/Model)**: "*should we expect everyone to be a coder and learn a specification language in order to perform data analysis?*"
- **Representation (Data/Model &rarr; Eyes)**
  - "deciding **what** to visualize is often equally, if not more, important, than deciding **how** to visualize it"
  - "how fancy does a visualization need to be in order to be useful for data analysis?"
    - "most visualization problems can be solved with a handful of graphs"
    - really hard to use, tweak, and combine graphs in clever/effective/innovative ways
- **Interpretation (Eyes &rarr; Mind)**
  - "what does one need to know in order to reason effectively about the results of modeling and visualization?"
  - "Are people able to interpret and trust their models?"
- Suggestions: Focus more on (more relevant) problems; More tools, less visualizations; Make it public

## Why visualize?
 

### Anscombes's quartet (1)

* @tbl-anscombe displays Anscombe's quartet [@Anscombe1973-xv], a dataset (or 4 little datasets) often used to illustrate the usefulness of visualization
	- Q: What does the table reveal about the data? Is it easy to read?
```{r tbl-anscombe, echo=FALSE, echo=FALSE, out.width = '100%'}
#| label: tbl-anscombe
#| tbl-cap: "Anscombe's quartett: Visualization"
anscombe_table <- anscombe %>% dplyr::select(x1, y1, x2, y2, x3, y3, x4, y4)
kable(anscombe_table, format = "html", table.attr = "style='width:95%;margin: auto;'",
      caption = "Anscombe's quartet data") %>%
  kable_styling(full_width = F) %>%
  column_spec(1, color = "red") %>%
  column_spec(2, color = "red") %>%
  column_spec(3, color = "blue") %>%
  column_spec(4, color = "blue") %>%
  column_spec(5, color = "darkgreen") %>%
  column_spec(6, color = "darkgreen") %>%
  column_spec(7, color = "orange") %>%
  column_spec(8, color = "orange")
```



 

### Anscombes's quartet (2)

* @tbl-regression-anscombe shows results from a linear regression based on Anscombe's quartet [@Anscombe1973-xv]
	- Q: What do we see now?
```{r tbl-regression-anscombe, echo=FALSE, echo=FALSE, results = "asis"}
#| label: tbl-regression-anscombe
#| tbl-cap: "Linear models based on sets of Anscombe's quartet"

fit1 <- lm(y1 ~ x1, data = anscombe)
fit2 <- lm(y2 ~ x2, data = anscombe)
fit3 <- lm(y3 ~ x3, data = anscombe)
fit4 <- lm(y4 ~ x4, data = anscombe)


models <- list("y1 (Set 1)" = fit1, 
							 "y2 (Set 2)" = fit2, 
							 "y3 (Set 3)" = fit3, 
							 "y4 (Set 4)" = fit4)
library(gt)
library(gtsummary)
library(modelsummary)
# additionally we want to change the font, font size and spacing
modelsummary(models,
output = 'gt',
notes = "Notes: some notes...",
gof_map = NA)
```






 
### Anscombes's quartet (3)

* @fig-anscombe finally visualizes the data underlying those data
    + Q: *What do we see here? What is the insight?*
```{r fig-anscombe, echo=FALSE, echo=FALSE, out.width = '100%'}
#| label: fig-anscombe
#| fig-cap: "Anscombe's quartet: Visualization"

anscombe_m <- data.frame()

for(i in 1:4)
  anscombe_m <- rbind(anscombe_m, data.frame(set=i, x=anscombe[,i], y=anscombe[,i+4]))

ggplot(anscombe_m, aes(x, y)) + 
    geom_point(size=3, color="black", fill="black", shape=21) + 
    geom_smooth(method="lm", fill=NA, fullrange=TRUE) + 
    facet_wrap(~set, ncol=2) +
    theme_light()
```




 

### The Datasaurus Dozen

* @fig-datasaurus-own displays the datasaurus dozen as animated by [Tom Westlake](https://github.com/thomasp85/gganimate/wiki/The-Datasaurus-Dozen) (see [here](https://github.com/thomasp85/gganimate/wiki/The-Datasaurus-Dozen), original by [Alberto Cairo](http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html))
    + Q: *What do we see here? What is the insight?*

```{r fig-datasaurus, eval=FALSE, fig.cap="The Datasaurus Dozen animated by Tom Westlake", include=FALSE, out.width="100%"}
#| label: fig-datasaurus
#| fig-cap: "The Datasaurus Dozen animated by Tom Westlake"
knitr::include_graphics("data/Datasaurus.gif")
```

```{r fig-datasaurus-own, echo=FALSE, warning=TRUE, out.width="100%"}
#| label: fig-datasaurus-own
#| fig-cap: "The Datasaurus Dozen animated by Tom Westlake"
library(gifski)
library(png)
library(datasauRus)
library(ggplot2)
library(gganimate)
library(dplyr)

datasaurus_dozen <- datasaurus_dozen %>% 
  group_by(dataset) %>%           
  mutate(mean.x = round(mean(x), 3),
         mean.y = round(mean(y),3),
         sd.x = round(sd(x), 3),
         sd.y = round(sd(y),3),
         cor.xy = round(cor(x,y),3)) %>%
  mutate(label = paste("Dataset: ", dataset, "\n",
                       "mean(x): ", mean.x, "\n",
                       "mean(y): ", mean.y, "\n",
                       "sd(y): ", sd.y, "\n",
                       "sd(x): ", sd.x, "\n",
                       "cor(x,y): ", cor.xy, sep=""))
           


ggplot(datasaurus_dozen, aes(x=x, y=y))+
  geom_point()+
  theme_minimal() +
  geom_text(x = 90, y = 85, aes(label = label)) +
  #geom_text(x = 80, y = 95, label=as.character(round(mean(~x),2))) +
  transition_states(dataset, 3, 1) + 
  ease_aes('cubic-in-out')
```



### Interactivity for data visualization

* "**interactive** data visualization enables direct actions on a plot to change elements and link between multiple plots" [@Swayne1999-wf] ([Wikipedia](https://en.wikipedia.org/wiki/Interactive_data_visualization))
* Interactivity revolutionizes the way we work with data
* Revolutionizes perception of data [cf. @Cleveland1984-fy]
* Started ~last quarter of the 20th century, PRIM-9 (1974) [@Friendly2006-aq, 23, see also Cleveland and McGill,
1988, Young et al. 2006]
* We have come a long way... ["evolution of animals"](http://stat-graphics.org/movies/prim9.html) (2:20, 3:20, Tukey inventor of boxplot)
* [More history](http://stat-graphics.org/movies/)
* Interactivity allows for...
    + ...making sense of big data (more dimensions)
    + ...exploring data
    + ...making data accessible to those without background
    + Online publishing, Interactive analysis/reading
    + My current projects: [www.digitalpolitics.info](https://paulcbauer.github.io/digitalpolitics/) ([older example](https://paulcbauer.shinyapps.io/transformations_of_variables/))
* Example: Check out the datablogs of various newspapers... [data journalism](http://www.theguardian.com/data)!




## Shiny

### What is Shiny?

A **web application framework** for R to turn analyses into interactive web applications.. what does that mean?

* The userinterface is a **webpage**
* On this webpage you can manipulate things
* Behind the webpage there is a computer (your computer or a **server**)
* That computer/server runs R and the R script of the webapp
* When you change something on the webpage, the information is send to the computer
* Computer runs the script with the new **inputs** (**input functions**)
* Computer sends back **outputs** to the webpage  (**output functions**)
* History of Shiny: [The Past and Future of Shiny](https://www.youtube.com/watch?v=HpqLXB_TnpI)






### Pro & contra Shiny
#### Pros of R Shiny:

1. **Fast Prototyping**: Shiny is excellent for quickly turning ideas into applications, and is relatively easy to use even for those who aren't seasoned programmers.
2. **Interactivity**: Shiny lets you build interactive web apps, enhancing user engagement and experience. It's especially beneficial for creating dashboards where data can be displayed in an interactive way.
3. **Integration with R Ecosystem**: Shiny integrates seamlessly with R's vast ecosystem. This includes integrating with packages for data manipulation, statistics, machine learning, and visualization.
5. **Statistical Modeling and Visualization**: Shiny allows you to apply complex statistical modeling and visualizations within your app, leveraging R's strong capabilities in these areas.
7. **No Need for Web Development Skills**: With Shiny, you can create web apps using R code alone. Knowledge of HTML, CSS, or JavaScript is not necessary, though it can help you to create more custom apps.
8. **Reactivity**: Shiny's reactivity system is excellent. It makes it possible to create applications that automatically update outputs in response to changes in inputs.
9. **Sharing and Publishing**: Shiny apps can be easily published and shared, either through RStudio's Shiny server, Shinyapps.io, or embedding in R Markdown documents or websites.

#### Cons of R Shiny:

1. **Performance**: Shiny apps run on top of R, an interpreted language, which can cause performance issues when handling large amounts of data or complex calculations.
2. **Single-threaded**: R (and by extension Shiny) is single-threaded, which can also cause performance issues when dealing with many simultaneous users.
3. **Complexity**: While Shiny's basics are easy to learn, mastering the intricacies of reactivity can be challenging.
5. **Limited Customization**/**Limited Mobile/Responsive Design**: Shiny provides flexibility, but customization can be limited, especially when compared with building a web app from scratch with JavaScript; Customization limited to advanced knowledge in CSS and JavaScript (but `shinyMobile` etc.)
8. **Data Gathering and Saving**: It can be challenging to use Shiny for gathering and saving data to the database.
9. **IT Support**/**Maintenance Cost**: Traditional IT support skills for Shiny may be limited, requiring developers to have a broader skill set; The cost of maintaining a Shiny application over time, including server costs and personnel time, can be high.
11. **Software Dependencies**: Certain Shiny applications may have many software dependencies, which can be challenging to manage and could potentially lead to issues down the line.
12. **Code Structure**: When a Shiny app grows in complexity, maintaining a clean and manageable code structure can be difficult (but **modularization with tree structure!**).
14. **Deployment**: Deployment of Shiny apps on a server may require
13. **Internationalization Issues** (but `shiny.i18n`); **Asynchronous Support** (but `promises`); **Multi-page Apps** (but `brochure`)





### The Guerry Dashboard: The app we will built
- In the workshop we will built the Shiny app shown in @fig-guerrydashboard together. Please [explore this app here](https://paulbauer.shinyapps.io/guerry_dashboard/) (5-10 minutes) and answer the following questions:
  - What questions can we answer using the app?
  - How can this help us to understand and analyze the underlying data?
  - What interactive elements did you identify in the app?

![(Source: Original image)](02-guerrydashboard.png){#fig-guerrydashboard}






### Components of a Shiny app
* As depicted in @fig-shinycomponents, a Shiny app has **two components**, the **user interface (UI)** and the **server**, that are passed as arguments to the `shinyApp()` which creates a Shiny app object from this **ui/server pair**

![Source: https://hosting.analythium.io/the-anatomy-of-a-shiny-application/ (c) Analythium](02-compontents-shiny-app.png){#fig-shinycomponents}



### Your (first) Shiny app
* Below you will create you first app and we'll use the opportunity to discuss the basic elements of a shiny app (see [here for more](https://mastering-shiny.org/basic-app.html#basic-app)).
* Install the relevant packages:

```{r, cache=TRUE, eval=FALSE, include=TRUE}
install.packages("shiny")
install.packages("tidyverse")
# Guerry package is already installed
```

* Create a directory with the name of your app "myfirstapp" in your [working directory](https://bookdown.org/ndphillips/YaRrr/the-working-directory.html).

* Create an rscript file that you call `"`app.R`.
* Copy the code below and paste it into your `app.R` script.

```{r, cache=TRUE, eval=FALSE, include=TRUE}
library(shiny)
library(Guerry)
library(tidyverse)


## Data: Clean & prepare data ----
guerry <- Guerry::gfrance85 %>%
  st_as_sf() %>%
  as_tibble() %>%
  st_as_sf(crs = 27572) %>%
  mutate(Region = case_match(
    Region,
    "C" ~ "Central",
    "E" ~ "East",
    "N" ~ "North",
    "S" ~ "South",
    "W" ~ "West"
  )) %>%
  select(!any_of(c("CODE_DEPT", "COUNT", "AVE_ID_GEO", "dept"))) %>%
  st_drop_geometry() %>%
  select(1:6)


# UI ----

ui <- dashboardPage( # start UI
  title = "The Guerry Dashboard",

  ### Header ----
  header = dashboardHeader(
    title = tagList(
      img(src = "workshop-logo.png", width = 35, height = 35),
      span("The Guerry Dashboard", class = "brand-text")
    )
  ),

  ### Sidebar ----
  sidebar = dashboardSidebar(
    id = "sidebar",
    sidebarMenu(
      id = "sidebarMenu",
      menuItem(tabName = "insp", 
               text = "Table data", 
               icon = icon("table"))
    )
  ),
  ### Body ----
  body = dashboardBody(
    tabItems( # start tabItems

      tabItem(
        tabName = "insp",
        hr(),
        DT::dataTableOutput("insp_table")
      )
      
    ) # end tabItems
  )
) # End UI



# Server ----

server <- function(input, output, session) {

  ## Create table ----
  dt <- reactive({

    DT::datatable(
      guerry,
      class = "hover",
      selection = "none",
      filter = list(position = "top", clear = FALSE),
      rownames = FALSE
    )
    
  })
  
  ## Render table ----
  output$insp_table <- DT::renderDataTable(dt(), server = FALSE)
  
}

shinyApp(ui, server)
```

* You can run and stop the app by clicking **Run App** (@fig-runappbutton) button in the document toolbar.

```{r run-app, out.width = NULL, echo = FALSE}
#| label: fig-runappbutton
#| fig-cap: " The Run App button can be found at the top-right of the source pane."
knitr::include_graphics("02-run-app.png")
```




### Loading things in Shiny apps

#### When is code run?
* When is code in a shiny app run? ([Source](https://shiny.posit.co/r/getstarted/shiny-basics/lesson5/#:~:text=Shiny%20will%20run%20code%20placed,the%20life%20of%20the%20app.))

![alt text](resources/run-once.png)
![alt text](resources/run-once-per-user.png)
![alt text](resources/run-many-times.png)

* Q: So where shall we put the function to load the dataset?
* Q: What problem might occur if we place certain code wrongly, e.g., load the data in the server or render function?





#### Where to load things
* Code outside ```server <- function(input, output) {}``` is run once, when you launch your app
* Code inside ```server <- function(input, output) {}``` is run once each time a user visits your app
* Code inside ```render*``` functions is rerun constantly (not only when user changes widget value, see [reactivity(https://shiny.posit.co/r/articles/build/understanding-reactivity/)]) 
* That means...
    + Load **Source scripts, libraries, and data** outside of ```server``` function (at the beginning)
        + Store data in ```www/``` folder in your app directory
        + Access with ```read.table("www/swiss.csv", sep=",")```
        + Access online data by inserting the url into the ```read*``` function (e.g. ```read.table()```)
    + **User specific objects** (e.g. object that records user's session information) are defined inside shinyServer’s unnamed function, but outside of any render* calls
        + e.g. user registers himself, user data as input data (compare income)
    + **Code/objects that are affected by choices in widgets** must be placed within the a ```render*``` function
        + Shiny reruns code in a ```render*``` chunk each time a user changes a widget mentioned in the chunk
* **Avoid** placing code within render function that does not need to be there... for performance reasons!


### Data storage
- Copy Jonas's part on data storage


## Minimum viable product (MVP)
* ...useful concept when building apps!
* "**version** of a product with **just enough features to be usable** by early customers who can then provide feedback for future product development." ([Wikipedia](https://en.wikipedia.org/wiki/Minimum_viable_product))
* "has **just enough core features to effectively deploy the product**, and no more. Developers typically **deploy the product to a subset of possible customers**, such as early adopters who are thought to be more forgiving, more likely to give feedback, and able to grasp a product vision from an early prototype or marketing information. This strategy targets **avoiding building products that customers do not want** and seek to **maximize information about the customer with the least money spent**. [...] falls under the Lean Startup methodology as MVPs aim to test business hypotheses [...]." ([Wikipedia](https://en.wikipedia.org/wiki/Minimum_viable_product))
* ..we follow the same strategy, slowly building out our shiny app and adding features & complexity

- CHECK & ADd: https://blog.crisp.se/wp-content/uploads/2016/01/Making-sense-of-MVP-.jpg


## Workflow: Development, debugging and getting help
- See discussions of workflow in @wickham2021mastering [Ch. 5, 20.2.1]
- Three important Shiny workflows:
  - Basic development cycle of creating apps, making changes, and experimenting with the results.
  - Debugging, i.e., figure out what’s gone wrong with your code/brainstorm solutions
  - Writing reprexes, self-contained chunks of code that illustrate a problem (essential for getting others' help)



### Development workflow
1. **Creating the app**: start every app with the same six lines of R code (`Shift + Tab` or in menue `New Project -> Shiny Web Application`)

```{r}
library(shiny)
ui <- fluidPage(
)
server <- function(input, output, session) {
}
shinyApp(ui, server)
```

2. **Seeing your changes**: you'll create a few apps a day, but you'll run apps hundreds of times, so mastering the development workflow is particularly important
  1. Write some code.^[**Automated testing**: allows you to turn interactive experiments you're running into automated code, i.e., run tests more quickly and not forget them (because they are automated). Requires more initial investment.]
  2. Launch the app with `Cmd/Ctrl + Shift + Enter`.
  3. Interactively experiment with the app.
  4. Close the app.
  5. Go to 1.
  
3. **Controlling the view**: Default is a pop-out window but you can also choose `Run in Viewer Pane` and `Run External`.

### Debugging workflow
* Guaranteed that something will go wrong at the start
* Cause is mismatch between your mental model of Shiny, and what Shiny actually does
* We need to develop **robust workflow for identifying and fixing mistakes**
* Three main cases of problems: **(1) Unexpected error**, **(2) No error but incorrect values**; **(3) Correct values but not updated**
  - (1) Use traceback and interactive debugger
  - (2) Use interactive debugger
  - (3) Problem unique to Shiny, i.e., R skills don't help
* See @wickham2021mastering [Ch. 5.2, [link](https://mastering-shiny.org/action-workflow.html#debugging)] for explanations and examples


